{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing guides using EasyGuide\n",
    "\n",
    "### Summary:\n",
    "- For simple black-box guides, try `pyro.contrib.autoguide`.\n",
    "- For more complex guides, use `pyro.contrib.easyguide`.\n",
    "- Decorate with `@easy_guide(model)`.\n",
    "- Select multiple model sites using `group = self.group(match=\"my_regex\")`.\n",
    "- Guide a group of sites by a single distribution using `group.sample(...)`.\n",
    "- Inspect concatenated group shape using `group.batch_shape`, `group.event_shape`, etc.\n",
    "- Use `self.plate(...)` instead of `pyro.plate(...)`.\n",
    "- To be compatible with subsampling, pass the `event_dim` arg to `pyro.param(...)`.\n",
    "- To MAP estimate model site \"foo\", use `foo = self.map_estimate(\"foo\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.easyguide import easy_guide, numel\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from torch.distributions import constraints\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('0.3.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a time-series model with a slowly-varying continuous latent state and Bernoulli observations with a logistic link function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(batch, subsample, full_size):\n",
    "    batch = list(batch)\n",
    "    num_time_steps = len(batch)\n",
    "    drift = pyro.sample(\"drift\", dist.LogNormal(-1, 0.5))\n",
    "    with pyro.plate(\"data\", full_size, subsample=subsample):\n",
    "        z = 0.\n",
    "        for t in range(num_time_steps):\n",
    "            z = pyro.sample(\"state_{}\".format(t),\n",
    "                            dist.Normal(z, drift))\n",
    "            batch[t] = pyro.sample(\"obs_{}\".format(t),\n",
    "                                   dist.Bernoulli(logits=z),\n",
    "                                   obs=batch[t])\n",
    "    return torch.stack(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_size = 100\n",
    "num_time_steps = 7\n",
    "pyro.set_rng_seed(123456789)\n",
    "data = model([None] * num_time_steps, torch.arange(full_size), full_size)\n",
    "assert data.shape == (num_time_steps, full_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a possible guide for this model where we point-estimate the `drift` parameter using a `Delta` distribution, and then model local time series using shared uncertainty but local means, using a `LowRankMultivariateNormal` distribution. There is a single global sample site which we can model with a `param` and `sample` statement. Then we sample a global pair of uncertainty parameters `cov_diag` and `cov_factor`. Next we sample a local `loc` parameter using `pyro.param(..., event_dim=...)` and an auxiliary sample site. Finally we unpack that site into one element per time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 8\n",
    "    \n",
    "def guide(batch, subsample, full_size):\n",
    "    num_time_steps = len(batch)\n",
    "\n",
    "    # MAP estimate the drift.\n",
    "    drift_loc = pyro.param(\"drift_loc\", lambda: torch.tensor(0.1),\n",
    "                           constraint=constraints.positive)\n",
    "    drift = pyro.sample(\"drift\", dist.Delta(drift_loc))\n",
    "\n",
    "    # Model local states using shared uncertainty + local mean.\n",
    "    cov_diag = pyro.param(\"state_cov_diag\",\n",
    "                          lambda: torch.full((num_time_steps,), 0.01),\n",
    "                         constraint=constraints.positive)\n",
    "    cov_factor = pyro.param(\"state_cov_factor\",\n",
    "                            lambda: torch.randn(num_time_steps, rank) * 0.01)\n",
    "    with pyro.plate(\"data\", full_size, subsample=subsample):\n",
    "        # Sample local mean.\n",
    "        loc = pyro.param(\"state_loc\",\n",
    "                         lambda: torch.full((full_size, num_time_steps), 0.5),\n",
    "                         event_dim=1)\n",
    "        states = pyro.sample(\"states\",\n",
    "                             dist.LowRankMultivariateNormal(loc, cov_factor, cov_diag),\n",
    "                             infer={\"is_auxiliary\": True})\n",
    "        # Unpack the joint states into one sample site per time step.\n",
    "        for t in range(num_time_steps):\n",
    "            pyro.sample(\"state_{}\".format(t), dist.Delta(states[:, t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(guide, num_epochs=1 if smoke_test else 101, batch_size=10):\n",
    "    full_size = data.size(-1)\n",
    "    pyro.get_param_store().clear()\n",
    "    pyro.set_rng_seed(123456789)\n",
    "    svi = SVI(model, guide, Adam({\"lr\": 0.02}), Trace_ELBO())\n",
    "    for epoch in range(num_epochs):\n",
    "        pos = 0\n",
    "        losses = []\n",
    "        while pos < full_size:\n",
    "            subsample = torch.arange(pos, pos + batch_size)\n",
    "            batch = data[:, pos:pos + batch_size]\n",
    "            pos += batch_size\n",
    "            losses.append(svi.step(batch, subsample, full_size=full_size))\n",
    "        epoch_loss = sum(losses) / len(losses)\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"epoch {} loss = {}\".format(epoch, epoch_loss / data.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@easy_guide(model)\n",
    "def guide(self, batch, subsample, full_size):\n",
    "    # MAP estimate the drift.\n",
    "    drift = self.map_estimate(\"drift\")\n",
    "\n",
    "    # Model local states using shared uncertainty + local mean.\n",
    "    group = self.group(match=\"state_[0-9]*\")\n",
    "    cov_diag = pyro.param(\"state_cov_diag\",\n",
    "                          lambda: torch.full(group.event_shape, 0.01),\n",
    "                          constraint=constraints.positive)\n",
    "    cov_factor = pyro.param(\"state_cov_factor\",\n",
    "                            lambda: torch.randn(group.event_shape + (rank,)) * 0.01)\n",
    "    with self.plate(\"data\", full_size, subsample=subsample):\n",
    "        # Sample local mean.\n",
    "        loc = pyro.param(\"state_loc\",\n",
    "                         lambda: torch.full((full_size,) + group.event_shape, 0.5),\n",
    "                         event_dim=1)\n",
    "        # Automatically sample the joint latent, then unpack and replay model sites.\n",
    "        group.sample(\"states\", dist.LowRankMultivariateNormal(loc, cov_factor, cov_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next consider an amortized guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@easy_guide(model)\n",
    "def guide(self, batch, subsample, full_size):\n",
    "    num_time_steps = len(batch)\n",
    "    drift = self.map_estimate(\"drift\")\n",
    "\n",
    "    group = self.group(match=\"state_[0-9]*\")\n",
    "    if not hasattr(self, \"nn\"):\n",
    "        self.nn = torch.nn.Linear(numel(group.event_shape),\n",
    "                                  numel(group.event_shape))\n",
    "        self.nn.weight.data.fill_(1.0 / num_time_steps)\n",
    "        self.nn.bias.data.fill_(-0.5)\n",
    "    loc = self.nn(batch.t())\n",
    "    cov_diag = pyro.param(\"state_cov_diag\",\n",
    "                          lambda: torch.full(group.event_shape, 0.01),\n",
    "                          constraint=constraints.positive)\n",
    "    cov_factor = pyro.param(\"state_cov_factor\",\n",
    "                            lambda: torch.randn(group.event_shape + (rank,)) * 0.01)\n",
    "    with self.plate(\"data\", full_size, subsample=subsample):\n",
    "        group.sample(\"states\", dist.LowRankMultivariateNormal(loc, cov_factor, cov_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
